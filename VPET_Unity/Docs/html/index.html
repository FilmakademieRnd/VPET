<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Dreamspace - VPET: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Dreamspace - VPET
   &#160;<span id="projectnumber">1.0.0</span>
   </div>
   <div id="projectbrief">Tablet App for on-set virtual content editing</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Packages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Dreamspace - VPET Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1>VPET</h1>
<h3>Description</h3>
<p>"Virtual Production Editing Tool" (VPET) is a tablet based onset editing application to work within a virtual production environment. It's an easy to use tool to make changes during a virtual shooting and synchronize those edits with the film pipeline. VPET communicate through a network interface with the main applications as well other clients and allows live editing of object and lighting parameters. </p>
<h3>Features</h3>
<ul>
<li>
Receiving virtual set from host application (currently Katana only) containing geometry, textures, lights, cameras and scene hierarchy  </li>
<li>
Realtime visualization </li>
<li>
Navigate through scene using touch inpute and tablet gyro </li>
<li>
Select and manipulate assets through various tools </li>
<li>
Instantly sending changes back to host </li>
<li>
Show and edit animations </li>
<li>
Connect to Ncam server and synchronize camera </li>
</ul>
<h3>Basic work flow:</h3>
<ul>
<li>
Setup LiveView on the host machine including the SceneDistributionPlugIn. Run it. </li>
<li>
Alternatively load scene in Katana and LiveRender the scene with the SceneDistributionPlugIn. </li>
<li>
Setup scene in Unity or load VPET_Client scene. </li>
<li>
Connect tablet and "Build and run" the application. This compiles and push the content to the tablet. </li>
<li>
Alternatively simply run the app from Unity. </li>
</ul>
<h1>Setup</h1>
<h3>Preparation:</h3>
<ul>
<li>
Install Unity 5 from: <a href="http://unity3d.com/get-unity">http://unity3d.com/get-unity</a> (the personal (free) edition is sufficient) </li>
<li>
</li>
<li>
Android Studio/SDK and it's requirements (JDK) is needed: <a href="http://developer.android.com/sdk/index.html">http://developer.android.com/sdk/index.html</a> to release builts for tablet </li>
<li>
Create a new Unity project or open existing  </li>
<li>
Download the unity package from the repository <a href="https://github.com/FilmakademieRnd/VPET/raw/master/VPET_Unity/VPET.unitypackage">https://github.com/FilmakademieRnd/VPET/raw/master/VPET_Unity/VPET.unitypackage</a>  </li>
<li>
Alternatively pull the GIT repository: <a href="https://github.com/FilmakademieRnd/VPET">https://github.com/FilmakademieRnd/VPET</a> and find the package in /VPET_Unity/ </li>
<li>
Import the package in the Unity project through Assets/Import Package/Custom  </li>
<li>
Select all an press import  </li>
</ul>
<h3>Open project:</h3>
<ul>
<li>
Run Unity </li>
<li>
On the first page select "Open other" and navigate to the folder "TabletRemote - Unity 5" within the repository </li>
<li>
Click "Select Folder" </li>
<li>
Now the assets are loading (this will take a while, but only at first startup) </li>
<li>
After all Assets are loaded, you can open the EmptyScene, MinimumScene or the MainScene in the Project Tab (bottom of the screen) </li>
</ul>
<h3>Use the VPET_Client Scene</h3>
<ul>
<li>
Run Unity and open the project  </li>
<li>
From Assets/VPET/Scenes/ open VPET_Client  </li>
<li>
This scene contains setup ready for streaming  </li>
<li>
In the Hierarchy Tab (on the left) all components beeing used are present  </li>
<li>
Objects will be sort under scene/root  </li>
<li>
You do not need to modify anything within the folders GUI, Controller or IO  </li>
</ul>
<h1>Functionality</h1>
<p>The app already includes a big amount of functionality that is usable for on-set asset editing. In this paragraph all functions will be listed.</p>
<h3>Config Widget</h3>
<ul>
<li>
The configuration screen allows you change a few basic settings.  </li>
<li>
IP Address is the IP of the server for requesting a scene and communicating updates.  </li>
<li>
"Load from cache" forces the app to load a scene from the resources folder. See below.  </li>
<li>
"Use texture" Uncheck this if you want to save memory on your hardware.  </li>
<li>
"Debug" is a toggle to display message at the top of the application.  </li>
<li>
The config widget can be accesses through the main menu any time.  </li>
</ul>
<h3>Config File</h3>
<ul>
<li>
VPET looks for the config file Assets/VPET/editing_tool.cfg and reads colon separated key value pairs per line. Every value which key matches a public property in <a href="_v_p_e_t_settings_8cs.html" class="el">VPETSettings.cs</a> will be used from config file.  </li>
<li>
Common property examples: <br />
 serverIP:172.17.21.188<br />
 doLoadFromResource:False<br />
 sceneFileName:MySceneName<br />
 doLoadTextures:True </li>
</ul>
<h3>Menus</h3>
<ul>
<li>
The main menu can be unfolded by tapping on the button in the upper right corner.  </li>
<li>
A circular menu is shown whenever an object is selected, this menu will contain only elements relevant to the selected object.  </li>
</ul>
<h3>Navigation</h3>
<ul>
<li>
On Android and Windows Tablets, simply rotating the tablet will rotate the virtual camera accordingly  </li>
<li>
The initial rotation can be defined, by tapping the "Calib" button in the main menu. (Only the y-axis value will be affected.)  </li>
<li>
When dragging two fingers on the screen, the viewport is translated on x and y-axis of the image plane.  </li>
<li>
When dragging three fingers on the screen vertically, the viewport is translated on z-axis (fly towards the scene or backwards).  </li>
<li>
When tapping on the on the main menu button showing a camera, the "point-to-move the camera" mode is activated. When activated you can position the tablets viewport by clicken on the target position on the ground. (Like in google street-view)  </li>
<li>
When tapping the ncam button in the main menu, the viewport will be synchronized with the ncam camera view (if available). You can now look into the virtual scene from the perspective of the camera tracked by ncam. Scene editing will remain possible.  </li>
</ul>
<h3>Object Selection</h3>
<ul>
<li>
You can select objects by clicking on them.  </li>
<li>
Deselect them by tapping on an empty space or a non-selectable object.  </li>
<li>
When tapping on another selectable object, the selection will be swapped immediately to this object.  </li>
</ul>
<h3>Object Manipulation:</h3>
<ul>
<li>
When an object gets selected a circular menu will be shown, that provides you all available manipulation tools. </li>
<li>
In clockwise order, these are the tools: </li>
<li>
<div class="image">
<img src="../images/EditMode_Translate_nrm.png"  style="float: left; width: 15px; margin-right: 5px;"/>
</div>
<div class="image">
<img src="../images/EditMode_Rotate_nrm.png"  style="float: left; width: 15px; margin-right: 5px;"/>
</div>
<div class="image">
<img src="../images/EditMode_Scale_nrm.png"  style="float: left; width: 15px; margin-right: 5px;"/>
</div>
There are standard modifiers (known from common CAD software) available to translate, rotate and scale objects. </li>
<li>
<div class="image">
<img src="../images/EditMode_TranslateAttachToCam_nrm.png"  style="float: left; width: 15px; margin-right: 5px;"/>
</div>
The object can be linked to the camera by the next button. The object can now be positioned by rotating the tablet or moving the tablets viewport, street-view like positioning is enabled in the mode as well. </li>
<li>
<div class="image">
<img src="../images/EditMode_GravityOn_nrm.png"  style="float: left; width: 15px; margin-right: 5px;"/>
</div>
You can disable gravity to be applied to this object with the thereon following button. </li>
<li>
<div class="image">
<img src="../images/EditMode_TranslateFingerSwipe_nrm.png"  style="float: left; width: 15px; margin-right: 5px;"/>
</div>
A multi-touch widget allows you to rotate the object with one finger, translate it on he image plane with two fingers, and push it into the scene or nearer to the camera with three fingers. </li>
<li>
<div class="image">
<img src="../images/EditMode_TranslateClickToMove_nrm.png"  style="float: left; width: 15px; margin-right: 5px;"/>
</div>
Last, you can position objects in a street-view like manner by clicking on the crosshairs. </li>
</ul>
<h3>Light Manipulation:</h3>
<ul>
<li>
When an light source gets selected a circular menu will be shown, that provides you all available manipulation tools. </li>
<li>
A selected light will additionally visualize the emitted light according to the light type (point light -&gt; sphere, spot light -&gt; cone, directional light -&gt; arrow) </li>
<li>
Scaling and gravitation enabling is hidden in the light menu, since they are not available for lights. </li>
<li>
Additionally to the already presented tools, buttons are added to access light related parameters. Through those you can manipulate color, intensity and cone angle of the light source. </li>
</ul>
<h3>Save streamed scene</h3>
<ul>
<li>
Through Unity you can save a streamed scene in binary format. Then copy these into your project and build it into the App for offline loading.  </li>
<li>
Set the basename of the scene at the IO/ServerAdapter within Unity.  </li>
<li>
Alternatively set the basename in the config file. The value from the config file is prior.  </li>
<li>
At the ServerAdapter make sure "Do write scene" is checked.  </li>
<li>
Run the app in the Editor, set the proper IP address and start the transfer. .  </li>
<li>
Three files have been written in a temporary folder: basename_nodes.bytes, basename_objec.bytes, basename_textu.bytes. See the Unity console output for the target location.  </li>
</ul>
<h3>Load chached scene</h3>
<ul>
<li>
To load a cached scene place the three binary files (nodes,objec,textu) in Assets/Resources/VPET/SceneDumps.  </li>
<li>
Set the basename of the scene at the IO/ServerAdapter within Unity.  </li>
<li>
Alternatively set the basename in the config file. This is helpful if you want change the scene after the project was built. The value from the config file is prior.  </li>
<li>
Run the app and in the configuration widget check "Load from cache".  </li>
</ul>
<h1>Setup new Scene</h1>
<h3>How to edit camera parameters:</h3>
<ul>
<li>
open the Cameras folder from the Hierarchy </li>
<li>
select the "Main Camera" (not the RenderInFrontCamera) and change position, rotation, fov, clipping planes in the Inspector (on the right) </li>
<li>
all settings will be automatically synchronized on startup with the second camera (RenderInFrontCamera) </li>
</ul>
<h3>How to add a movable and selectable object:</h3>
<ul>
<li>
import the asset (best is .fbx) via drag'n'drop to the Project folder (bottom of the screen) </li>
<li>
then drag'n'drop the asset from the project folder to the Scene folder in the Hierarchy (on the left) (all assets need to be placed in the Scene folder) </li>
<li>
attach the SceneObject script (located in Project folder -&gt; Scripts) by dragging it onto the asset </li>
</ul>
<h3>How to add a static not selectable object:</h3>
<ul>
<li>
import the asset (best is .fbx) via drag'n'drop to the Project folder (bottom of the screen) </li>
<li>
then drag'n'drop the asset from the project folder to the Scene folder in the Hierarchy (on the left) (all assets need to be placed in the Scene folder) </li>
<li>
attach the StaticHitObject script (located in Project folder -&gt; Scripts) by dragging it onto the asset </li>
</ul>
<h3>How to add add a light source:</h3>
<ul>
<li>
create a new light source from GameObject-&gt;Light (point-, spot- and directional lights are currently supported) </li>
<li>
place it in the Scene folder in the Hierarchy </li>
<li>
attach the LightQuad prefab from Project-&gt;Resources as child to the new light asset (drag'n'drop) </li>
<li>
spot light: attach the Cone prefab from Project-&gt;Resources as child to the new light asset (drag'n'drop) </li>
<li>
point light: attach the Sphere prefab from Project-&gt;Resources as child to the new light asset (drag'n'drop) </li>
<li>
directional light: attach the Arrow prefab from Project-&gt;Resources as child to the new light asset (drag'n'drop) </li>
</ul>
<h3>How to build for Google Project Tango Developer kit:</h3>
<ul>
<li>
use Unity version 5.3.7. (see <a href="https://unity3d.com/de/get-unity/download/archive" target="new">archive</a> for older versions)</li>
<li>
update the Tango Core of your device to version 1.48:2016.12.13</li>
<li>
switch to Android build  </li>
<li>
import Tango Unity package Caporales (version 1.49, January 2017)  </li>
<li>
activate Tango manager  </li>
<li>
activate Tango object  </li>
<li>
add variable USE_TANGO to Player Settings / Other Settings / Scripting Define Symbols  </li>
</ul>
<h3>How to build for Lenovo Phab 2 Pro with Tango support:</h3>
<ul>
<li>
follow steps above for Google Tango Devkit</li>
<li>
enable 'Tango Build 4 Lenovo Phab 2' checkbox in Main Camera</li>
</ul>
<br>
</ul>
<h1>Compilation</h1>
<h3>For a windows tablet:</h3>
<ul>
<li>
In Unity go to File-&gt;Build settings </li>
<li>
Select "PC, Mac &amp; Linux Standalone" as Platform </li>
<li>
Select "Windows" as Target Platform </li>
<li>
Select "x86_64" as Architecture (import! - otherwise the sensor reading on windows tablets will not work) </li>
<li>
Info: Sensors are accessed on Windows through a separate dynamic library (native library). The source of the library can be found in VPET_Unity/WindowsSensorWrapper. This became necessary since Unity does not implement sensor access for Windows desktop builds, but only for Windows Store apps. </li>
<li>
next click build </li>
</ul>
<h3>For an android tablet:</h3>
<ul>
<li>
Download the Android SDK Tools from: <a href="https://developer.android.com/sdk/index.html">https://developer.android.com/sdk/index.html</a> </li>
<li>
Navigate to the Android Tools folder and download the SDK for your Android version with the SDKManager.exe as described here: <a href="https://developer.android.com/sdk/installing/adding-packages.html">https://developer.android.com/sdk/installing/adding-packages.html</a> </li>
<li>
Download &amp; install the Java Development Kit (JDK) </li>
<li>
In Unity go to Edit-&gt;Preferences-&gt;External Tools. </li>
<li>
Set the "Android SDK Location" and the "JDK location" to the folders you installed those tools. </li>
<li>
Now go to File-&gt;Build settings </li>
<li>
Select "Android" as Platform </li>
<li>
Click build </li>
</ul>
<h1>Network communication</h1>
<ul>
<li>
All manipulations applied to scene objects and lights are communicated to a synchronisation server and the Katana server. </li>
<li>
For this communication netMQ is used, the .net implementation of zeroMQ (<a href="http://zeromq.org/">http://zeromq.org/</a>).  </li>
</ul>
<h3>How to connect the tablet app to the servers:</h3>
<ul>
<li>
in the Unity project navigate to IO-&gt;ServerAdapter in the Hierarchy Tab (left side) </li>
<li>
in the inspector (right side) enter the IP address of the synchronization server and the katana server (ports are set automatically, if a wrong formated IP address is set, communication will automatically be disabled)  </li>
<li>
unselect "deactivate receive" (to be able to receive messages from the synchronization server) </li>
<li>
unselect "deactivate publish" (to be able to push messages to the synchronization server) </li>
<li>
unselect "deactivate publish katana" (to be able to push messages to the katana server) </li>
<li>
Important notice: An intermediate synchronization server is always required. Although you can easily replace the provided server to just receive updates from one tablet. </li>
</ul>
<h3>Receiving messages with python:</h3>
<ul>
<li>
When you are using only one tablet you can directly grab messages from that tablet, otherwise you can grab all messages from the synchronization server </li>
<li>
If you have python installed you can install the python binding of zeroMQ either with easy_install or pip (follow instructions on: <a href="http://zeromq.org/bindings:python">http://zeromq.org/bindings:python</a>) </li>
<li>
Note: You can also use implementations of zeroMQ for other languages. </li>
<li>
the following python scripts will receive all messages coming from the the tablet app and print them to console: </li>
<li>
With intermediate synchronization server:<br />
<br />
 <code> import zmq<br />
 <br />
 context = zmq.Context()<br />
 socket = context.socket(zmq.SUB)<br />
 socket.connect("tcp://000.000.000.000:5556") #change IP to the synchronization IP<br />
 socket.setsockopt(zmq.SUBSCRIBE, "client")<br />
 socket.setsockopt(zmq.SUBSCRIBE, "ncam")<br />
 socket.setsockopt(zmq.SUBSCRIBE, "recorder")<br />
 <br />
 while True :<br />
 message = socket.recv()<br />
 topic, messagedata = message.split()<br />
 print(messagedata)<br />
 </code>  </li>
<li>
Direct listening to tablet:<br />
<br />
 <code> import zmq<br />
 <br />
 context = zmq.Context()<br />
 socket = context.socket(zmq.SUB)<br />
 socket.bind("tcp://000.000.000.000:5557") #change IP to the IP of the computer this script is running on<br />
 socket.setsockopt(zmq.SUBSCRIBE, "client")<br />
 <br />
 while True :<br />
 message = socket.recv()<br />
 topic, messagedata = message.split()<br />
 print(messagedata) </code>  </li>
</ul>
<h3>The communication protocol:</h3>
<ul>
<li>
Each message is distributed by netMQ. </li>
<li>
A message is a standard string, containing all necessary values. </li>
<li>
example message: "client 129|r|CubeParent/Cube|0.01386935|-0.1318762|-0.6923447|0.7092779|physics" </li>
<li>
the fist part of the string (before the space) is the topic (used by the netMQ Publish/Subscribe Pattern) <ul>
<li>
available topics that can be subscribed to are: </li>
<li>
"client": updates coming directly from clients (tablets) </li>
<li>
"ncam": ncam data (position, rotation, focal length) for each frame (only available when using the provided synchronization server) </li>
<li>
"record": the synchronization server stores the current scene state and is thereby able to provide an initialisation update to new subscribers (this functionality is in BETA status and is not yet reliable) </li>
</ul>
</li>
<li>
all values of the core message are separated by a single "|" </li>
<li>
first value is a unique id of the sender </li>
<li>
second value is the type of information sent <ul>
<li>
available types are: </li>
<li>
r: rotation </li>
<li>
t: translation </li>
<li>
s: scale </li>
<li>
c: light color </li>
<li>
i: light intensity </li>
<li>
a: light spot angle </li>
<li>
d: light range </li>
<li>
k: kinematic change (enables/disables gravity for an object) </li>
<li>
l: lock bool (locks an object if edited by one client to avoid editing on two clients at the same time) </li>
<li>
f: focal length of the ncam camera </li>
</ul>
</li>
<li>
third value is the path to the light or object <ul>
<li>
only exception is the path within ncam data, which is always simply "cam"  </li>
<li>
otherwise this path is relative to the Scene folder </li>
<li>
separation is done with a single "/" (which is natively supported by Unity) </li>
</ul>
</li>
<li>
those three values are followed by the actual new values <ul>
<li>
number of values for each data type: <ul>
<li>
r: 4 floats (quaternion) </li>
<li>
t: 3 floats (xyz) </li>
<li>
s: 3 floats (xyz) </li>
<li>
c: 3 floats (rgb) range: 0 to 1 </li>
<li>
i: 1 float range: 0 to 8 </li>
<li>
a: 1 float range: 0 to 179 (in degree, including penumbra angle) </li>
<li>
d: 1 float range: 0 to infinity </li>
<li>
k: 1 bool </li>
<li>
l: 1 bool </li>
<li>
f: 1 float </li>
</ul>
</li>
</ul>
</li>
<li>
A translation and rotation message can have an additional (optional) last value <ul>
<li>
this value will always be "physics" </li>
<li>
if this is attached to the massage, the rotation or translation is related to a physics interaction with the scene </li>
<li>
On clients having an active physics engine (e.g. other tablets), those messages should be ignored, physics can be directly calculated on that client </li>
<li>
On clients without physics engine (e.g. standard renderers), those messages provide the possibility to see the physics interaction and can be handled as normal scene updates </li>
</ul>
</li>
</ul>
<h1>App structure:</h1>
<div class="image">
<img src="../images/app_structure.png"  style="width: 1500px;"/>
</div>
 <h1>Release Notes</h1>
<h3>Release 1.0.0</h3>
<ul>
<li>
Synchronized release current state with latest improvements and bug fixes </li>
<li>
Tested with: SceneDistributionPlugIn 1.0.3, SynchronizationServer 0.1.0  </li>
<li>
Updated doxy files </li>
</ul>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Sep 27 2016 10:15:30 for Dreamspace - VPET by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
